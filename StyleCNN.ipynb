{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  \n",
    "# If 'cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Gram matrix layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class GramMatrix(nn.Module):\n",
    "    def forward(self, input):\n",
    "        a, b, c, d = input.size()\n",
    "        features = input.view(a * b, c * d)\n",
    "        G = torch.mm(features, features.t())\n",
    "        return G.div(a * b * c * d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define style CNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "\n",
    "class StyleCNN(object):\n",
    "    # Model parameters\n",
    "    def __init__(self, style, content, pastiche):\n",
    "        super(StyleCNN, self).__init__()\n",
    "    \n",
    "        self.style = style\n",
    "        self.content = content\n",
    "        self.pastiche = nn.Parameter(pastiche.data)\n",
    "        \n",
    "        self.content_layers = ['conv_4']\n",
    "        self.style_layers = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']\n",
    "        self.content_weight = 1\n",
    "        self.style_weight = 1000\n",
    "        \n",
    "        self.cnn = models.vgg19(pretrained=True) # pre-trained CNN\n",
    "        \n",
    "        self.gram = GramMatrix() # Gram matrix for computing style loss\n",
    "        self.loss = nn.MSELoss() # Loss function \n",
    "        self.optimizer = optim.LBFGS([self.pastiche])\n",
    "        \n",
    "        # Cuda device\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.cnn.cuda()\n",
    "            self.gram.cuda()\n",
    "    \n",
    "    # Training step\n",
    "    def step(self):\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        pastiche = self.pastiche.clone()\n",
    "        pastiche.data.clamp_(0, 1)\n",
    "        content = self.content.clone()\n",
    "        style = self.style.clone()\n",
    "\n",
    "        content_loss = 0\n",
    "        style_loss = 0\n",
    "\n",
    "        i = 1\n",
    "        not_inplace = lambda layer: nn.ReLU(inplace=False) if isinstance(layer, nn.ReLU) else layer\n",
    "        for layer in list(self.cnn.features):\n",
    "            layer = not_inplace(layer)\n",
    "            if self.use_cuda:\n",
    "                layer.cuda()\n",
    "\n",
    "            pastiche, content, style = layer.forward(pastiche), layer.forward(content), layer.forward(style)\n",
    "\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                name = \"conv_\" + str(i)\n",
    "                \n",
    "                # Increment content loss at certain conv layers\n",
    "                if name in self.content_layers:\n",
    "                    content_loss += self.loss(pastiche * self.content_weight, content.detach() * self.content_weight)\n",
    "                \n",
    "                # Increment style loss at certain conv layers\n",
    "                if name in self.style_layers:\n",
    "                    pastiche_g, style_g = self.gram.forward(pastiche), self.gram.forward(style)\n",
    "                    style_loss += self.loss(pastiche_g * self.style_weight, style_g.detach() * self.style_weight)\n",
    "\n",
    "            # Increment conv layer counter\n",
    "            if isinstance(layer, nn.ReLU):\n",
    "                i += 1\n",
    "        \n",
    "        return content_loss, style_loss\n",
    "    \n",
    "    # Closure for LBFGS\n",
    "    def closure(self):\n",
    "        self.content_loss, self.style_loss = self.step()\n",
    "        total_loss = self.content_loss + self.style_loss\n",
    "        total_loss.backward()\n",
    "        \n",
    "        return total_loss\n",
    "    \n",
    "    # Training Procesure\n",
    "    def train(self):\n",
    "        self.optimizer.step(self.closure)\n",
    "        return self.content_loss, self.style_loss, self.pastiche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from PIL import Image\n",
    "import imageio\n",
    "\n",
    "imsize = 256\n",
    "\n",
    "loader = transforms.Compose([\n",
    "             transforms.Resize((imsize, imsize)),\n",
    "             transforms.ToTensor()\n",
    "         ])\n",
    "\n",
    "unloader = transforms.ToPILImage()\n",
    "\n",
    "def load_image(image_name):\n",
    "    image = Image.open(image_name)\n",
    "    image = Variable(loader(image))\n",
    "    image = image.unsqueeze(0)\n",
    "    return image\n",
    "  \n",
    "def save_image(input, path):\n",
    "    image = input.data.clone().cpu()\n",
    "    image = image.view(3, imsize, imsize)\n",
    "    image = unloader(image)\n",
    "    imageio.imwrite(path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Content loss: 6.625802\n",
      "Style loss: 48.774509\n",
      "Iteration: 10\n",
      "Content loss: 1.582543\n",
      "Style loss: 0.273035\n",
      "Iteration: 20\n",
      "Content loss: 1.339626\n",
      "Style loss: 0.185075\n",
      "Iteration: 30\n",
      "Content loss: 1.299487\n",
      "Style loss: 0.175296\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "# CUDA Configurations\n",
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "\n",
    "# Content and style\n",
    "style = load_image(\"styles/starry_night.jpg\").type(dtype)\n",
    "content = load_image(\"contents/building.jpg\").type(dtype)\n",
    "\n",
    "pastiche = load_image(\"contents/building.jpg\").type(dtype)\n",
    "pastiche.data = torch.randn(pastiche.data.size()).type(dtype)\n",
    "\n",
    "# Declare the network\n",
    "style_cnn = StyleCNN(style, content, pastiche)\n",
    "   \n",
    "num_epochs = 31\n",
    "for i in range(num_epochs):\n",
    "    content_loss, style_loss, pastiche = style_cnn.train()\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(\"Iteration: %d\" % (i))\n",
    "        print(\"Content loss: %f\" % (content_loss.item()))\n",
    "        print(\"Style loss: %f\" % (style_loss.item()))\n",
    "            \n",
    "        path = \"outputs/%d.png\" % (i)\n",
    "        pastiche.data.clamp_(0, 1)\n",
    "        save_image(pastiche, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
